# Digit Recognizer: Сравнение классических моделей и нейросетей

Решение классической задачи распознавания рукописных цифр (MNIST) с комплексным сравнением классических алгоритмов машинного обучения и нейронных сетей. Проект включает полный цикл: от исследования данных до развертывания моделей и создания сабмитов для Kaggle.

## Результаты

| Модель | Accuracy (Val) | Kaggle Score |
| :--- | :---: | :---: |
| **CNN (Simple)** | **0.9914** | **0.9880** |
| XGBoost | 0.9752 | 0.9734 |
| CatBoost | 0.9745 | - |
| Random Forest | 0.9663 | - |
| SGD Classifier | 0.8931 | - |
| Advanced MLP | 0.9774 | - |
| Simple MLP | 0.9763 | - |

**Лучшая модель:** Простая сверточная нейронная сеть (CNN) показала наивысшую точность.

## Технологии

*   **Язык:** Python 3
*   **Анализ данных:** Pandas, NumPy, Matplotlib, Seaborn
*   **Классические ML:** Scikit-learn, XGBoost, CatBoost
*   **Нейронные сети:** PyTorch
*   **Оптимизация:** Кастомный GridSearch, ранняя остановка
*   **Валидация:** Stratified Split, кросс-валидация

## Реализованные подходы

### 1. Классические алгоритмы
*   **Градиентный бустинг:** XGBoost и CatBoost с подбором гиперпараметров и early stopping.
*   **Ансамбли:** Random Forest с ручным подбором сетки параметров.
*   **Линейные модели:** SGDClassifier с кастомной логикой обучения батчами и эпохами.
*   **Кастомный GridSearch:** Реализован собственный эффективный поиск по сетке с поддержкой батчевого обучения.

### 2. Нейронные сети (PyTorch)
*   **Полносвязные сети (MLP):** Простая и усложненная архитектуры с Dropout и BatchNorm.
*   **Сверточные сети (CNN):** Архитектура с двумя сверточными и пулинговыми слоями.
*   **Процесс обучения:** Использованы DataLoader, стандартизация, ранняя остановка, оптимизатор Adam.

### 3. Анализ данных
*   Визуализация распределения классов.
*   Отображение случайных примеров изображений.
*   Стратифицированное разделение на train/val.

